整理自AWS Blog https://aws.amazon.com/blogs/database/key-components-of-a-data-driven-agentic-ai-application/

Agentic AI能够提升生产效率，解决传统软件不能解决的问题，简化集成，找到之前不可见的答案。 Agentic AI系统自动决定如何以及调用何种action（动作）来完成一个任务，并能随着更多信息来逐步调整计划。但是，这里还需要人工的操作，需要人工通过自然语言给出提示词，并进行管控。人类聚焦在目标上，agent聚焦在找到完成目标需要执行的细节上。当人机交互界面发生变化时，AgentAI系统仍然可以依赖于相同的后端来完成任务。以买玩具汽车为例，Agentic AI系统能够调用购买、库存更新、物流以及订单确认的工作流，在这些工作流中需要调用相同的后端服务和数据库。但问题是：Agentic AI系统是否能够直接和数据库来交互来获取库存信息或者调用信用卡网络API来付费？也就是：Agentic AI系统通过什么方式与数据交互？

在这篇博客中，作者探讨了直接数据库访问来替代智能体AI服务的成本、收益和缺点，包括在生产中验证过的有效的方式，以及还需要构建的服务。

**Agentic AI 系统的架构**

Agentic AI应用的核心是一个循环（loop）。当用户让系统完成一项任务时，工作流就进入了一个event loop，在这个loop中会不断迭代，直至认为完成了任务或回答了用户的问题。系统可能会回到用户那里寻求更多信息。这个loop实际上就是Reason+Act（ReAct）loop，是Agentic AI系统最流行的设计模式。

![Agentic AI设计Loop](https://d2908q01vomqb2.cloudfront.net/887309d048beef83ad3eabf2a79a64a389ab1c9f/2025/10/02/DBBLOG-5187-2.png)


ReAct模式被广泛应用在各式Agent中，比如Chatbot，商业流程自动化Agent、研究类Agent等。实现过程中，可以利用**Agent开发框架**如StrandsAgent、LangGraph，**托管服务**如Amazon Bedrock AgentCore，以及**用户Agent应用**如Amazon Q Business、Q Developer、Claude Desktop等。实现这类Agent，通常需要考虑如下模块：

1.上下文管理模块。负责为每一轮循环检索、汇聚和过滤所需数据。数据来源包括会话状态、历史记忆（如会话历史、用户偏好等）以及工具执行结果。检索数据后，该模块会选择最相关的信息放入下一轮LLM调用的上下文窗口中。

2.推理和规划模块。负责理解用户意图，结合相关上下文来制定或调整行动计划。该模块会判断当前信息是否足够回答用户问题，如果不够就继续执行循环，将每次的结果保存到记忆中，直到完成用户任务。

3.工具/Action执行模块。使用可用工具来执行完成用户任务的具体行动。该模块接收推理和规划模块提供的参数作为工具调用的输入，然后将执行结果传递给上下文管理模块，用于下一轮循环。

这个架构使得Agentic AI应用能够在设计范围内，通过多轮Event Loop来完成指定的任务。在执行任务过程中，Event Loop循环次数越多，系统效率越低。由于LLM调用次数不可预测，会带来不确定的输入/输出token消耗，进而影响成本和性能。从Event Loop中跳出来向用户获取更多数据同样也会影响成本和性能。接下来我们来看有哪些机制可以优化这个loop和用户体验。


**Agentic AI应用的上下文管理模块**

尽管AI Agent获得了大模型的复杂推理能力，但它们面临着这些模型固有的两个关键限制。首先，大模型是无状态的，无法记住过去的交互或维护上下文。其次，大模型有限的上下文窗口限制了每一步能够处理的数据量。

上下文管理模块帮助开发者管理Agent每次Event Loop迭代的上下文窗口。上下文工程是指在Agent执行的每一步中仔细选择要包含在上下文窗口中的正确信息的艺术和科学。这些信息可能包括用户指令（系统和用户提示词、工具描述等）、先前的记忆（会话历史、用户偏好等）、外部知识（企业知识库、权威数据源等）、工具执行结果（API调用结果）以及其他数据源。

当Agent执行循环时，可能会从这些数据源积累大量信息，这可能导致上下文超出LLM的上下文窗口，因此聚合先前交互的数据并不是有效的解决方案。即使对于支持上下文窗口中大量token的LLM模型，推理的有效性也会随着上下文量的增加而衰减，使Agent更容易产生幻觉、忽略有价值的信息或无法执行任务。因此，仔细过滤和选择最有价值的数据包含在每次LLM推理的上下文窗口中至关重要。

Agent访问的数据源包括：

*指令*

LLM交互的指令包括系统提示词、用户提示词、工具选择信息以及结果示例。系统提示词为Agent提供角色、能力、个性和约束等指令。用户提示词是用户的直接请求。工具选择信息是Agent选择正确工具执行任务所需的上下文数据。

*短期记忆*

短期记忆包括会话（Session）和状态（State）。Session存储对话和任务执行中交互的时间顺序流。类似于Web应用的session，会话数据需要快速访问近期交互历史，采用临时存储方式，并设置基于时间的自动过期机制。State相当于Agent为每个特定交互准备的专用记事本。Agent使用State存储空间来存放和更新任务执行期间所需的动态详细信息，如待办事项列表及其执行进度。在考虑存储此类数据的合适基础设施时，需要考虑高频更新、可配置的保留策略、会话结束时的内存清理以及细粒度的会话级访问控制。像Q Developer、Claude Code和Cline这样的本地Agent通常使用文件系统存储Session和State信息。在线Agent可以使用专门的短期记忆服务，如Bedrock AgentCore短期记忆或Amazon ElastiCache for Valkey等缓存服务。（注：Amazon DynamoDB/DocumentDB/Aurora PostgreSQL也都是可以考虑的选项）

*长期记忆*

长期记忆包括Agent随时间积累的事实、关系以及学习到的行为模式。有了长期记忆，Agent在与每个客户交互或解决问题时不需要从头开始。记忆使Agent能够利用先前的成功模式、学到的上下文以及对客户的了解，通过更少的客户交互轮次更快地解决问题。

在Agent收集了大量信息后（通常在会话结束时），它可以执行并行的记忆提取过程。该过程涉及将Session和State数据传递给LLM来识别相关信息。新提取的记忆可以存储在向量数据库中以供后续相似性搜索，或存储在关系数据库中以支持更确定性的查询。（注：客户可以自己配置什么时候来触发长期记忆的提取，另外也可以调用一些框架来进行信息抽取，比如Mem0）

存储长期记忆对数据库的技术需求包括向量搜索和预过滤能力，以缩小搜索范围并改善查找延迟。Bedrock AgentCore的记忆原语提供了这些功能，以及自定义的分块和摘要策略。开发者也可以选择Aurora PostgreSQL或OpenSearch Service将向量与应用数据保持在一起。

为了改善记忆检索，开发者可以将向量搜索与知识图谱结合起来（GraphRAG）。开发者可以在知识图谱中将记忆组织为相互连接的实体和关系，使Agent能够理解复杂的依赖关系并基于连接的信息进行推理。Amazon Neptune Analytics提供了图定义、检索和动态关系创建支持，用于从知识图谱中存储和检索记忆。（注：AI Coding可以将代码的调用关系等存储到知识图谱中，来进行检索）

*外部知识库*

知识库是结构化和非结构化信息的集中存储库，作为AI应用的基础数据。它们包括文档、FAQ、产品规格、程序、最佳实践和特定领域的专业知识。数据库如Aurora PostgreSQL将文本存储为高维向量（Embedding），支持理解上下文和含义而不仅仅是关键词匹配的向量搜索语义级别的向量检索。这些功能对于Agent使用向量搜索检索最相关信息以识别语义相似性至关重要。开发者还可以使用专门的RAG服务如Amazon Bedrock Knowledge Bases创建知识库，该服务提供端到端的RAG管理工作流。

*从工具执行过程中检索到的数据信息*

工具充当AI Agent和外部系统之间的桥梁，实现动态数据访问。Agent可以通过工具检索各种数据类型，如实时信息（天气、股价、新闻）、计算结果（计算、数据分析）以及外部API数据（CRM记录、库存水平）。有了适当的上下文，推理和规划组件可以确定完成用户任务的最有效路径。

**Agentic AI应用的推理和规划模块**

推理和规划组件收集最终用户问题和来自先前event loop迭代的所有上下文，并将其作为输入提交给LLM进行推理。发送给LLM的上下文包括经过上下文管理模块过滤的最关键数据，包括指令、记忆、知识库中的数据，以及数据库相关的工具。从LLM接收的响应可以是三个选项之一：

*回应用户*

LLM推理输出可以包含对用户的响应，表明任务已完成（或在极少数情况下，Agent因错误或其他原因放弃）。

*向用户询问更多信息*

与回应用户类似，此选项将期望用户的回应。有了用户在上下文中的额外数据，系统可以开始新的event loop迭代。

*选择要调用的工具*
LLM推理输出可以包含指定要调用哪个工具（工具选项作为系统提示的一部分提供）和调用该工具要使用的输入参数的指令。

Agentic AI系统通常比我们这里描述的更复杂，因为它们需要最小化完成任务所需的event loop迭代次数，并在LLM调用方面更加谨慎，以实现最佳性价比。高级推理和规划组件可能使用规则或LLM将用户问题分解为完成任务所需的一系列行动（步骤）。某些计划的行动可能并行执行（如果它们不相互依赖），从而减少延迟（例如，Strands允许LLM使用批处理接口并行调用工具）。对于其他行动，确定行动计划的初始LLM响应可能已经提供了所需的输入参数，从而避免在工具调用之前进行另一次LLM调用。如果需要单独的LLM调用来推导工具输入参数，可能可以使用更小的专用LLM或小型语言模型（SLM）。这些优化改善了延迟并降低了推理成本。

一种新兴的设计模式将一些次要的LLM调用转移到工具本身。例如，设计用于在关系数据库上执行查询的工具可能接受自然语言，然后自己调用LLM生成相应的SQL查询，然后连接到数据库并执行查询。该工具可以使用针对生成SQL查询优化的模型，而不是更大的通用模型。这样的工具实际上本身就是一个Agent，有自己的event loop，迭代尝试生成的查询，直到获得正确的查询。在这种将Agent作为工具的模式中，主Agent的记忆不会被工具中失败查询尝试的上下文污染。（参考：[开放协议促进Agent互操作性：MCP上的Agent间通信](https://aws.amazon.com/blogs/opensource/open-protocols-for-agent-interoperability-part-1-inter-agent-communication-on-mcp/)）

**工具调用模块**
